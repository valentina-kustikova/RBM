{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e63f0d",
   "metadata": {},
   "source": [
    "# Ограниченная машина Больцмана (Restricted Boltzmann machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa260e0",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641c006",
   "metadata": {},
   "source": [
    "<b> Ограниченная машина Больцмана (RBM) </b> — это генеративная стохастическая искусственная нейронная сеть, которая определяет распределение вероятности на наборе входных данных.\n",
    "\n",
    "Как следует из их названия, RBM являются вариантом машин Больцмана с ограничением, что их нейроны должны образовывать двудольный граф: пара узлов, сформированная из нейронов двух групп (обычно называемых «видимыми» и «скрытыми» соответственно), имеет симметричное соединение между собой, и нет никаких связей между узлами внутри группы. Это ограничение позволяет использовать более эффективные алгоритмы обучения, чем те, которые доступны для общего класса машин Больцмана, в частности, алгоритм контрастной дивергенции на основе градиента. Кроме того, особенностью ограниченных машин Больцмана является возможность прохождения обучение без учителя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2c978",
   "metadata": {},
   "source": [
    "## Обозначения и вывод формул"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b28afe",
   "metadata": {},
   "source": [
    "Введем следующие обозначения:\n",
    "* Состояния нейронов видимого слоя\n",
    "$$v_1, v_2, ..., v_{N_v}; v_i \\in \\{0, 1\\}, i = \\overline{1, N_v}, v \\in R^{N_v}$$\n",
    "* Состояния нейронов скрытого слоя\n",
    "$$h_1, h_2, ..., h_{N_h}; h_i \\in \\{0, 1\\}, i = \\overline{1, N_h}, h \\in R^{N_h}$$\n",
    "* Матрица связей между нейронами видимого и скрытого слоя\n",
    "$$W \\in R^{N_v \\times N_h}$$\n",
    "* Веc между i-ым нейроном видимого слоя и j-ым нейроном скрытого слоя\n",
    "$$w_{ij}, i = \\overline{1, N_v}, j = \\overline{1, N_h}$$\n",
    "* Смещение видимого нейрона\n",
    "$$a_i, i = \\overline{1, N_v}$$\n",
    "* Смещение скрытого нейрона\n",
    "$$b_j, j = \\overline{1, N_h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960923b5",
   "metadata": {},
   "source": [
    "![RBM1](https://raw.githubusercontent.com/Frixinglife/RBM/adb5aa904ca892d3be8f05867935dc8075efc052/images/RBM1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f7216",
   "metadata": {},
   "source": [
    "### Энергия и вероятности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a14193",
   "metadata": {},
   "source": [
    "* Введем понятие энергии для ограниченной машины Больцмана:\n",
    "$$E(v, h) = -\\sum_{i=1}^{N_v}a_iv_i-\\sum_{j=1}^{N_h}b_jh_j-\\sum_{i=1}^{N_v}\\sum_{j=1}^{N_h}w_{ij}v_ih_j=-a^\\top v-b^\\top h - v^\\top W h$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949e0b4",
   "metadata": {},
   "source": [
    "* Вероятность всевозможных пар v и h:\n",
    "$$p(v, h) = \\frac{1}{Z}e^{-E(v, h)},$$\n",
    "где Z — это статсумма следующего вида (суммирование по всевозможным векторам v и h):\n",
    "$$Z = \\sum_{v'}\\sum_{h'} e^{-E(v', h')}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b716f9",
   "metadata": {},
   "source": [
    "* Полная вероятность вектора v (суммирование по всевозможным векторам h):\n",
    "$$p(v) = \\frac{1}{Z}\\sum_{h'} e^{-E(v, h')}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c51610",
   "metadata": {},
   "source": [
    "### Вычисление условных вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bdd71a",
   "metadata": {},
   "source": [
    "* Вероятность того, что при данном v скрытое состояние h<sub>j</sub> = 1:\n",
    "$$p(h_j = 1|v) = \\frac{e^{-E(v,h_j = 1)}}{e^{-E(v,h_j = 1)} + e^{-E(v,h_j = 0)}}=\\frac{1}{1 + e^{E(v,h_j = 1)-E(v,h_j = 0)}}=\\frac{1}{1 + e^{-b_j-\\sum_{i=1}^{N_v}w_{ij}v_i}}=\\sigma(b_j+\\sum_{i=1}^{N_v}w_{ij}v_i),$$\n",
    "где\n",
    "$$\\sigma(z)=\\frac{1}{1 + e^{-z}}$$\n",
    "сигмоидальная функция"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea4f97",
   "metadata": {},
   "source": [
    "* Вероятность того, что при данном h видимое состояние v<sub>i</sub> = 1:\n",
    "$$p(v_i = 1|h) = \\frac{e^{-E(v_i = 1,h)}}{e^{-E(v_i = 1,h)} + e^{-E(v_i = 0,h)}}=\\frac{1}{1 + e^{E(v_i = 1,h)-E(v_i = 0,h)}}=\\frac{1}{1 + e^{-a_i-\\sum_{j=1}^{N_h}w_{ij}h_j}}=\\sigma(a_i+\\sum_{j=1}^{N_h}w_{ij}h_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7b0a9",
   "metadata": {},
   "source": [
    "* Поскольку при фиксированном v скрытые состояния h<sub>j</sub> независимы друг от друга (как и при фиксированном h видимые состояния v<sub>i</sub>), получаем:\n",
    "$$p(h|v)=\\prod_{j=1}^{N_h}p(h_j|v)$$\n",
    "$$p(v|h)=\\prod_{i=1}^{N_v}p(h|v_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bcdd65",
   "metadata": {},
   "source": [
    "### Цель обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea0ff8",
   "metadata": {},
   "source": [
    "Мы можем наблюдать состояния видимых нейронов, но не можем напрямую увидеть состояния скрытых. Несмотря на это, опираясь на наблюдаемые состояния, можно сделать вероятностный вывод относительно скрытых состояний. После обучения данной модели мы сможем делать вероятностные выводы (при помощи теоремы Байеса) о том, какими являются видимые нейроны, опираясь на скрытые. Таким образом, приходим к следующей <b>цели</b>:\n",
    "\n",
    "> Необходимо обучить модель таким образом (настроить её параметры), чтобы полученный в результате работы RBM вектор состояния был близок к первоначальному состоянию, из которого он был восстановлен.\n",
    "\n",
    "Данную цель можно достигнуть путем максимизации вероятности p(v). Кроме того, вместо максимизации вероятности p(v), можно максимизировать натуральный логарифм от нее (это удобнее для получения формул), поскольку он является строго возрастающей функцией."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f36a5e",
   "metadata": {},
   "source": [
    "### Максимизация вероятности p(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2537bcc",
   "metadata": {},
   "source": [
    "Найдем производную от натурального логарифма p(v) по весу w<sub>ij</sub>:\n",
    "$$\\frac{\\partial \\log(p(v))}{\\partial w_{ij}} = \\frac{1}{p(v)} \\frac{\\partial p(v)}{\\partial w_{ij}} = \\frac{1}{p(v)}\\frac{\\partial}{\\partial w_{ij}}(\\frac{\\sum_{h'} e^{-E(v, h')}}{Z})= \\frac{1}{p(v)}\\frac{\\frac{\\partial}{\\partial w_{ij}}(\\sum_{h'} e^{-E(v, h')})Z - \\sum_{h'} e^{-E(v, h')}\\frac{\\partial Z}{\\partial w_{ij}}}{Z^2},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb4afc6",
   "metadata": {},
   "source": [
    "где\n",
    "$$p(v) = \\frac{1}{Z}\\sum_{h'} e^{-E(v, h')}$$\n",
    "$$Z = \\sum_{v'}\\sum_{h'} e^{-E(v', h')}$$\n",
    "$$E(v, h) = -\\sum_{i=1}^{N_v}a_iv_i-\\sum_{j=1}^{N_h}b_jh_j-\\sum_{i=1}^{N_v}\\sum_{j=1}^{N_h}w_{ij}v_ih_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d0dbb",
   "metadata": {},
   "source": [
    "Вычислим производные:\n",
    "$$\\frac{\\partial}{\\partial w_{ij}}(\\sum_{h'} e^{-E(v, h')})=\\sum_{h'} v_ih_je^{-E(v, h')}$$\n",
    "$$\\frac{\\partial Z}{\\partial w_{ij}}=\\frac{\\partial}{\\partial w_{ij}}(\\sum_{v'}\\sum_{h'} e^{-E(v', h')})=\\sum_{v'}\\sum_{h'} v_ih_je^{-E(v', h')}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a53abb",
   "metadata": {},
   "source": [
    "После подстановки получаем:\n",
    "$$\\frac{\\partial \\log(p(v))}{\\partial w_{ij}}=\\frac{1}{p(v)}\\frac{\\frac{\\partial}{\\partial w_{ij}}(\\sum_{h'} e^{-E(v, h')})Z - \\sum_{h'} e^{-E(v, h')}\\frac{\\partial Z}{\\partial w_{ij}}}{Z^2}=$$\n",
    "$$=\\frac{Z}{\\sum_{h'} e^{-E(v, h')}}\\frac{Z(\\sum_{h'} v_ih_je^{-E(v, h')}) - (\\sum_{h'} e^{-E(v, h')})(\\sum_{v'}\\sum_{h'} v_ih_je^{-E(v', h')})}{Z^2}=$$\n",
    "$$=\\frac{\\sum_{h'} v_ih_je^{-E(v, h')}}{\\sum_{h'} e^{-E(v, h')}}-\\frac{\\sum_{v'}\\sum_{h'} v_ih_je^{-E(v', h')}}{Z}=$$\n",
    "$$=(\\frac{Z}{\\sum_{h'} e^{-E(v, h')}})(\\sum_{h'} v_ih_j\\frac{e^{-E(v, h')}}{Z})-\\sum_{v'}\\sum_{h'} v_ih_j\\frac{e^{-E(v', h')}}{Z}=$$\n",
    "$$=\\sum_{h'} v_ih_j\\frac{p(v,h')}{p(v)}-\\sum_{v'}\\sum_{h'} v_ih_jp(v',h')=$$\n",
    "$$=\\sum_{h'} v_ih_jp(h'|v)-\\sum_{v'}\\sum_{h'} v_ih_jp(v',h')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4786107",
   "metadata": {},
   "source": [
    "Таким образом, получаем:\n",
    "$$\\frac{\\partial \\log(p(v))}{\\partial w_{ij}}=\\sum_{h'} v_ih_jp(h'|v)-\\sum_{v'}\\sum_{h'} v_ih_jp(v',h')=\\mathsf{E}_{data}[v_ih_j]-\\mathsf{E}_{model}[v_ih_j],$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452eb1ba",
   "metadata": {},
   "source": [
    "где Е - математическое ожидание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa3e1b",
   "metadata": {},
   "source": [
    "Аналогично, можно получить формулы для производных по смещениям:\n",
    "$$\\frac{\\partial \\log(p(v))}{\\partial a_{i}}=\\mathsf{E}_{data}(v_i)-\\mathsf{E}_{model}(v_i), \\frac{\\partial \\log(p(v))}{\\partial b_{j}}=\\mathsf{E}_{data}(h_j)-\\mathsf{E}_{model}(h_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a582b5e",
   "metadata": {},
   "source": [
    "### Правила обновления параметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1b87e",
   "metadata": {},
   "source": [
    "Введем параметр η (learning rate), отвечающий за скорость обучения модели. Тогда получаем следующие правила обновления параметров модели (весов и смещений):\n",
    "$$\\Delta w_{ij}=\\eta(\\mathsf{E}_{data}[v_ih_j]-\\mathsf{E}_{model}[v_ih_j])$$\n",
    "$$\\Delta a_{i}=\\eta(\\mathsf{E}_{data}[v_i]-\\mathsf{E}_{model}[v_i])$$\n",
    "$$\\Delta b_{j}=\\eta(\\mathsf{E}_{data}[h_j]-\\mathsf{E}_{model}[h_j])$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
